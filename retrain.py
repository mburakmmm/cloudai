"""
Continuous Training Script
Yeni eklenen verilerle modeli yeniden eÄŸitmek (fine-tune) iÃ§in script
"""

import os
import sys
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import argparse

# Proje root'unu path'e ekle
sys.path.insert(0, os.path.dirname(__file__))

try:
    from src.data.database_manager import DatabaseManager
    from src.model.tokenizer import CustomTokenizer
    from src.model.transformer_model import GenerativeTransformer
    from src.data.data_loader import ConversationDataset
    from src.training.trainer import Trainer
    from src.training.config import get_config, get_model_config, get_training_config
    from src.data.preprocessor import TextPreprocessor
    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"âŒ ModÃ¼l import hatasÄ±: {e}")
    MODULES_AVAILABLE = False


class ContinuousTrainer:
    """SÃ¼rekli eÄŸitim sÄ±nÄ±fÄ±"""
    
    def __init__(self, 
                 base_model_path: str = "models/chatbot-v1",
                 fine_tune_epochs: int = 3,
                 learning_rate: float = 1e-5,
                 batch_size: int = 16):
        """
        ContinuousTrainer baÅŸlat
        
        Args:
            base_model_path: Temel model yolu
            fine_tune_epochs: Fine-tuning iÃ§in epoch sayÄ±sÄ±
            learning_rate: Fine-tuning learning rate
            batch_size: Batch boyutu
        """
        self.base_model_path = base_model_path
        self.fine_tune_epochs = fine_tune_epochs
        self.learning_rate = learning_rate
        self.batch_size = batch_size
        
        # VeritabanÄ± yÃ¶neticisi
        self.db_manager = DatabaseManager()
        
        # Text preprocessor
        self.preprocessor = TextPreprocessor(
            lowercase=True,
            remove_html=True,
            remove_emojis=False,
            min_length=10,
            max_length=500
        )
        
        # Model ve tokenizer
        self.model = None
        self.tokenizer = None
        self.trainer = None
        
        # EÄŸitim geÃ§miÅŸi
        self.training_history = []
        
        print(f"ğŸš€ ContinuousTrainer baÅŸlatÄ±ldÄ±")
        print(f"  ğŸ“ Base model: {base_model_path}")
        print(f"  ğŸ”„ Fine-tune epochs: {fine_tune_epochs}")
        print(f"  ğŸ“š Learning rate: {learning_rate}")
        print(f"  ğŸ“¦ Batch size: {batch_size}")
    
    def load_base_model(self) -> bool:
        """
        Temel modeli yÃ¼kle
        
        Returns:
            bool: YÃ¼kleme baÅŸarÄ±lÄ± mÄ±
        """
        try:
            print(f"ğŸ“‚ Temel model yÃ¼kleniyor: {self.base_model_path}")
            
            # Model konfigÃ¼rasyonu
            model_config = get_model_config()
            
            # Model oluÅŸtur
            self.model = GenerativeTransformer(
                vocab_size=model_config['vocab_size'],
                d_model=model_config['d_model'],
                nhead=model_config['nhead'],
                num_decoder_layers=model_config['num_decoder_layers'],
                dim_feedforward=model_config['dim_feedforward'],
                dropout=model_config['dropout']
            )
            
            # Model aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kle
            model_file = os.path.join(self.base_model_path, "pytorch_model.pth")
            if os.path.exists(model_file):
                self.model.load_state_dict(torch.load(model_file, map_location='cpu'))
                print(f"âœ… Model aÄŸÄ±rlÄ±klarÄ± yÃ¼klendi: {model_file}")
            else:
                print(f"âš ï¸ Model dosyasÄ± bulunamadÄ±: {model_file}")
                return False
            
            # Tokenizer yÃ¼kle
            tokenizer_path = os.path.join(self.base_model_path, "tokenizer")
            if os.path.exists(tokenizer_path):
                self.tokenizer = CustomTokenizer(vocab_size=model_config['vocab_size'])
                self.tokenizer.load(tokenizer_path)
                print(f"âœ… Tokenizer yÃ¼klendi: {tokenizer_path}")
            else:
                print(f"âš ï¸ Tokenizer bulunamadÄ±: {tokenizer_path}")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            return False
    
    def get_new_data_since(self, last_training_date: Optional[datetime] = None) -> List[Dict]:
        """
        Son eÄŸitimden bu yana eklenen yeni verileri al
        
        Args:
            last_training_date: Son eÄŸitim tarihi
            
        Returns:
            List[Dict]: Yeni veriler
        """
        try:
            # TÃ¼m konuÅŸmalarÄ± al
            df = self.db_manager.get_all_conversations()
            
            if df.empty:
                print("â„¹ï¸ VeritabanÄ±nda veri bulunamadÄ±")
                return []
            
            # Tarih filtreleme
            if last_training_date:
                df['created_at'] = pd.to_datetime(df['created_at'])
                df = df[df['created_at'] > last_training_date]
                print(f"ğŸ“… {last_training_date} tarihinden sonra eklenen veriler filtreleniyor...")
            
            # Veriyi dict formatÄ±na Ã§evir
            new_data = []
            for _, row in df.iterrows():
                # Metin temizleme
                clean_prompt = self.preprocessor.clean_text(row['prompt'])
                clean_response = self.preprocessor.clean_text(row['response'])
                
                if clean_prompt and clean_response:  # GeÃ§erli verileri filtrele
                    new_data.append({
                        'prompt': clean_prompt,
                        'response': clean_response,
                        'intent': row['intent'],
                        'lang': row.get('lang', 'tr'),
                        'created_at': row['created_at']
                    })
            
            print(f"ğŸ“Š {len(new_data)} yeni veri bulundu")
            return new_data
            
        except Exception as e:
            print(f"âŒ Veri alma hatasÄ±: {e}")
            return []
    
    def prepare_dataset(self, data: List[Dict]) -> ConversationDataset:
        """
        Veriyi dataset formatÄ±na hazÄ±rla
        
        Args:
            data: Ham veri
            
        Returns:
            ConversationDataset: HazÄ±rlanmÄ±ÅŸ dataset
        """
        try:
            print("ğŸ“š Dataset hazÄ±rlanÄ±yor...")
            
            # Metinleri birleÅŸtir
            texts = []
            for item in data:
                # Prompt ve response'u birleÅŸtir
                combined_text = f"{item['prompt']} {self.tokenizer.sep_token} {item['response']}"
                texts.append(combined_text)
            
            # Dataset oluÅŸtur
            dataset = ConversationDataset(
                dataframe=None,  # DataFrame kullanmÄ±yoruz
                texts=texts,
                tokenizer=self.tokenizer,
                max_length=256
            )
            
            print(f"âœ… Dataset hazÄ±rlandÄ±: {len(dataset)} Ã¶rnek")
            return dataset
            
        except Exception as e:
            print(f"âŒ Dataset hazÄ±rlama hatasÄ±: {e}")
            raise
    
    def fine_tune_model(self, dataset: ConversationDataset) -> Dict:
        """
        Modeli fine-tune et
        
        Args:
            dataset: EÄŸitim dataset'i
            
        Returns:
            Dict: EÄŸitim sonuÃ§larÄ±
        """
        try:
            print("ğŸ”§ Model fine-tuning baÅŸlÄ±yor...")
            
            # EÄŸitim konfigÃ¼rasyonu
            training_config = get_training_config()
            training_config.update({
                'num_epochs': self.fine_tune_epochs,
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size
            })
            
            # Trainer oluÅŸtur
            self.trainer = Trainer(
                model=self.model,
                dataset=dataset,
                config=training_config
            )
            
            # Fine-tuning
            results = self.trainer.train(
                num_epochs=self.fine_tune_epochs,
                batch_size=self.batch_size,
                validation_split=0.1,
                early_stopping_patience=3,
                save_every=1
            )
            
            print("âœ… Fine-tuning tamamlandÄ±!")
            return results
            
        except Exception as e:
            print(f"âŒ Fine-tuning hatasÄ±: {e}")
            raise
    
    def save_fine_tuned_model(self, version: str = None) -> str:
        """
        Fine-tune edilmiÅŸ modeli kaydet
        
        Args:
            version: Model versiyonu
            
        Returns:
            str: KayÄ±t yolu
        """
        try:
            if version is None:
                version = f"v{len(self.training_history) + 1}"
            
            # Model kaydet
            model_dir = self.trainer.save_model(version=version, include_tokenizer=True)
            
            # EÄŸitim geÃ§miÅŸine ekle
            training_record = {
                'version': version,
                'timestamp': datetime.now().isoformat(),
                'fine_tune_epochs': self.fine_tune_epochs,
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size,
                'data_count': len(self.training_history),
                'model_path': model_dir
            }
            
            self.training_history.append(training_record)
            
            # GeÃ§miÅŸi kaydet
            self._save_training_history()
            
            print(f"ğŸ’¾ Fine-tuned model kaydedildi: {model_dir}")
            return model_dir
            
        except Exception as e:
            print(f"âŒ Model kaydetme hatasÄ±: {e}")
            raise
    
    def _save_training_history(self):
        """EÄŸitim geÃ§miÅŸini kaydet"""
        history_file = "continuous_training_history.json"
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š EÄŸitim geÃ§miÅŸi kaydedildi: {history_file}")
    
    def run_continuous_training(self) -> bool:
        """
        SÃ¼rekli eÄŸitim dÃ¶ngÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±r
        
        Returns:
            bool: BaÅŸarÄ±lÄ± mÄ±
        """
        try:
            print("ğŸš€ SÃ¼rekli eÄŸitim baÅŸlatÄ±lÄ±yor...")
            
            # Temel modeli yÃ¼kle
            if not self.load_base_model():
                print("âŒ Temel model yÃ¼klenemedi!")
                return False
            
            # Son eÄŸitim tarihini al
            last_training = None
            if self.training_history:
                last_training = datetime.fromisoformat(self.training_history[-1]['timestamp'])
                print(f"ğŸ“… Son eÄŸitim: {last_training}")
            
            # Yeni verileri al
            new_data = self.get_new_data_since(last_training)
            
            if not new_data:
                print("â„¹ï¸ Yeni veri bulunamadÄ±. EÄŸitim gerekli deÄŸil.")
                return True
            
            # Dataset hazÄ±rla
            dataset = self.prepare_dataset(new_data)
            
            # Fine-tuning
            results = self.fine_tune_model(dataset)
            
            # Modeli kaydet
            model_path = self.save_fine_tuned_model()
            
            print(f"ğŸ‰ SÃ¼rekli eÄŸitim tamamlandÄ±!")
            print(f"  ğŸ“ Model: {model_path}")
            print(f"  ğŸ“Š SonuÃ§lar: {results}")
            
            return True
            
        except Exception as e:
            print(f"âŒ SÃ¼rekli eÄŸitim hatasÄ±: {e}")
            return False


def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(description="Cloud AI SÃ¼rekli EÄŸitim Script'i")
    parser.add_argument("--base-model", default="models/chatbot-v1", 
                       help="Temel model yolu")
    parser.add_argument("--epochs", type=int, default=3, 
                       help="Fine-tuning epoch sayÄ±sÄ±")
    parser.add_argument("--lr", type=float, default=1e-5, 
                       help="Learning rate")
    parser.add_argument("--batch-size", type=int, default=16, 
                       help="Batch boyutu")
    parser.add_argument("--auto", action="store_true", 
                       help="Otomatik sÃ¼rekli eÄŸitim")
    
    args = parser.parse_args()
    
    if not MODULES_AVAILABLE:
        print("âŒ Gerekli modÃ¼ller yÃ¼klenemedi!")
        return
    
    print("ğŸš€ Cloud AI - SÃ¼rekli EÄŸitim Script'i")
    print("=" * 50)
    
    # ContinuousTrainer oluÅŸtur
    trainer = ContinuousTrainer(
        base_model_path=args.base_model,
        fine_tune_epochs=args.epochs,
        learning_rate=args.lr,
        batch_size=args.batch_size
    )
    
    if args.auto:
        print("ğŸ”„ Otomatik sÃ¼rekli eÄŸitim modu...")
        while True:
            try:
                success = trainer.run_continuous_training()
                if success:
                    print("âœ… EÄŸitim tamamlandÄ±. 1 saat bekleniyor...")
                    time.sleep(3600)  # 1 saat bekle
                else:
                    print("âŒ EÄŸitim baÅŸarÄ±sÄ±z. 30 dakika bekleniyor...")
                    time.sleep(1800)  # 30 dakika bekle
            except KeyboardInterrupt:
                print("\nğŸ›‘ KullanÄ±cÄ± tarafÄ±ndan durduruldu.")
                break
            except Exception as e:
                print(f"âŒ Beklenmeyen hata: {e}")
                time.sleep(1800)  # 30 dakika bekle
    else:
        # Tek seferlik eÄŸitim
        success = trainer.run_continuous_training()
        if success:
            print("âœ… EÄŸitim baÅŸarÄ±yla tamamlandÄ±!")
        else:
            print("âŒ EÄŸitim baÅŸarÄ±sÄ±z!")
            sys.exit(1)


if __name__ == "__main__":
    main()
