import os
from src.model.tokenizer import CustomTokenizer
from src.data.database_manager import DatabaseManager

def train_tokenizer_fixed():
    print("ğŸ”§ Sabit Vocab Size ile Tokenizer EÄŸitimi...")
    
    # VeritabanÄ±ndan veri al
    db_manager = DatabaseManager()
    df = db_manager.get_all_conversations()
    
    if df.empty:
        print("âŒ VeritabanÄ±nda veri bulunamadÄ±!")
        return
    
    print(f"ğŸ“Š Toplam {len(df)} konuÅŸma bulundu")
    
    # Veri hazÄ±rla
    texts = []
    for _, row in df.iterrows():
        texts.append(row['prompt'])
        texts.append(row['response'])
    
    print(f"âœ… {len(texts)} metin hazÄ±rlandÄ±")
    
    # Tokenizer oluÅŸtur ve eÄŸit
    vocab_size = 8000  # Sabit deÄŸer
    tokenizer = CustomTokenizer(vocab_size=vocab_size)
    
    print(f"ğŸ“š Tokenizer {vocab_size} vocab size ile eÄŸitiliyor...")
    
    tokenizer.train(texts, save_path="models/tokenizer")
    
    print(f"âœ… Tokenizer eÄŸitimi tamamlandÄ±! Vocab size: {tokenizer.get_vocab_size()}")
    print(f"ğŸ’¾ Tokenizer kaydedildi: models/tokenizer")

if __name__ == "__main__":
    train_tokenizer_fixed()
